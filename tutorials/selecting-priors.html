<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>4.3. Selecting Priors &mdash; PyMsBayes 0.3.2 documentation</title>
    
    <link rel="stylesheet" href="../_static/pymsbayes.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.3.2',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/dpp.js"></script>
    <link rel="top" title="PyMsBayes 0.3.2 documentation" href="../index.html" />
    <link rel="up" title="4. PyMsBayes Tutorials" href="index.html" />
    <link rel="next" title="4.4. Getting the exampe data" href="get-example-data.html" />
    <link rel="prev" title="4.2. The Configuration File" href="configuration.html" /> 
  </head>
  <body>
<div id="header_wrap" class="outer">
    <header class="inner">
      <a id="forkme_banner" href="https://github.com/joaks1/PyMsBayes">View on GitHub</a>

      <h1 id="project_title"><a href="../index.html">PyMsBayes</a></h1>
      <h2 id="project_tagline">A multi-processing Python wrapper and API for approximate-Bayesian phylgeographical inference</h2>

        <section id="downloads">
          <a class="zip_download_link" href="https://github.com/joaks1/PyMsBayes/zipball/master">Download this project as a .zip file</a>
          <a class="tar_download_link" href="https://github.com/joaks1/PyMsBayes/tarball/master">Download this project as a tar.gz file</a>
        </section>
    </header>
</div>

    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="get-example-data.html" title="4.4. Getting the exampe data"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="configuration.html" title="4.2. The Configuration File"
             accesskey="P">previous</a> |</li>
<li><a href="../index.html">Home</a>&nbsp;|</li>
<li><a href="../intro/installation.html">Install</a>&nbsp;|</li>
<li><a href="../doc.html">Documentation</a>&nbsp;|</li>

          <li><a href="index.html" accesskey="U">4. PyMsBayes Tutorials</a> &raquo;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../doc.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">4.3. Selecting Priors</a><ul>
<li><a class="reference internal" href="#an-introduction-to-the-gamma-probability-distribution">4.3.1. An introduction to the gamma probability distribution</a><ul>
<li><a class="reference internal" href="#gamma-basics">4.3.1.1. Gamma basics</a></li>
<li><a class="reference internal" href="#using-r-to-help-visualize-gamma-priors">4.3.1.2. Using R to help visualize gamma priors</a></li>
</ul>
</li>
<li><a class="reference internal" href="#important-priors-for-the-dpp-msbayes-model">4.3.2. Important priors for the dpp-msbayes model</a><ul>
<li><a class="reference internal" href="#concentration-parameter-of-the-dirichlet-process">4.3.2.1. Concentration parameter of the Dirichlet process</a><ul>
<li><a class="reference internal" href="#an-important-point-about-the-concentration-parameter">4.3.2.1.1. <span class="hlight">An important point about the concentration parameter</span></a></li>
</ul>
</li>
<li><a class="reference internal" href="#population-size">4.3.2.2. Population size</a></li>
<li><a class="reference internal" href="#divergence-time">4.3.2.3. Divergence time</a></li>
<li><a class="reference internal" href="#bottleneck-proportions">4.3.2.4. Bottleneck proportions</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="configuration.html"
                        title="previous chapter">4.2. The Configuration File</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="get-example-data.html"
                        title="next chapter">4.4. Getting the exampe data</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="../_sources/tutorials/selecting-priors.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="selecting-priors">
<span id="id1"></span><h1>4.3. Selecting Priors<a class="headerlink" href="#selecting-priors" title="Permalink to this headline">¶</a></h1>
<div class="section" id="an-introduction-to-the-gamma-probability-distribution">
<span id="gamma-intro"></span><h2>4.3.1. An introduction to the gamma probability distribution<a class="headerlink" href="#an-introduction-to-the-gamma-probability-distribution" title="Permalink to this headline">¶</a></h2>
<p>dpp-msbayes uses the gamma probability distribution for priors on many of the
parameters in the model.
Thus, before we dive into all the priors of the dpp-msbayes model, it will be
helpful to</p>
<ol class="arabic simple">
<li><a class="reference internal" href="#gamma-basics"><em>introduce some basic characteristics of gamma
distributions</em></a></li>
<li><a class="reference internal" href="#gamma-in-r"><em>introduce some graphical tools to help us visualize and select gamma
priors</em></a></li>
</ol>
<div class="section" id="gamma-basics">
<span id="id2"></span><h3>4.3.1.1. Gamma basics<a class="headerlink" href="#gamma-basics" title="Permalink to this headline">¶</a></h3>
<p>All of the gamma priors in dpp-msbayes have two parameters: The shape
(<img class="math" src="../_images/math/0086f23ab7bc17b6437799654c17068f058a9b87.png" alt="\gshape"/>) and scale (<img class="math" src="../_images/math/bfb2e87065edcabde495be12ffc7acc1117dc286.png" alt="\gscale"/>) parameters.
With this parameterization, the mean and variance of a gamma distribution are
<img class="math" src="../_images/math/284fa1fd12e20c356e7b3a000bdb437c025a741a.png" alt="\gshape\gscale"/> and <img class="math" src="../_images/math/5424659e09aeced5b6fbe95353b66aba52699bc2.png" alt="\gshape\gscale^2"/>, respectively.</p>
<p>As you might have guessed, the shape parameter controls the shape of the
distribution, while the scale parameter controls the scale.
You can think of it this way: all gamma distributions with the same value of
the shape parameter have the same shape, and differences among them in the
scale parameter simply &#8220;re-scale&#8221; the x-axis.
When the shape is <img class="math" src="../_images/math/b8156da288ae79388d7db5b3dcc0fc7891222697.png" alt="\gshape = 1"/>, the gamma becomes an exponential
distribution with a mean of <img class="math" src="../_images/math/bfb2e87065edcabde495be12ffc7acc1117dc286.png" alt="\gscale"/>.
When the shape is less than or equal to 1, the mode, or &#8220;peak&#8221;, of the
distribution is at zero.
When the shape is greater than 1, the mode is greater than zero
(<img class="math" src="../_images/math/026e4a438f5037c8a79692fde6dec74bbb2fe649.png" alt="(\gshape-1)\gscale"/>).</p>
<p>When thinking about the gamma distribution as a prior, the shape parameter
represents how much <em>a priori</em> knowledge we have about a parameter.
A larger value means we are more certain about the value of the parameter <em>a
priori</em>, whereas a smaller means we are less certain.
The scale parameter simply &#8220;shifts&#8221; the distribution along the x-axis to &#8220;fit&#8221;
our prior expectations.</p>
</div>
<div class="section" id="using-r-to-help-visualize-gamma-priors">
<span id="gamma-in-r"></span><h3>4.3.1.2. Using R to help visualize gamma priors<a class="headerlink" href="#using-r-to-help-visualize-gamma-priors" title="Permalink to this headline">¶</a></h3>
<p>Let&#8217;s say we have prior knowledge that the value of a parameter is around 10.0,
and we are pretty sure that it&#8217;s greater than 5.0, but less than 15.0.
Because, we want the prior to be centered near 10.0, we can take advantage of
the fact that the mean of the gamma distribution should be around
<img class="math" src="../_images/math/278999dda003ca9643bedf3882a62a8d795b3f27.png" alt="\gshape\gscale = 10.0"/>.
We can use some quick-and-dirty R to get a rough idea of what a gamma prior
with this mean and a shape of 1.0 (i.e., an exponential prior) will look like:</p>
<div class="highlight-r"><div class="highlight"><pre><span class="o">&gt;</span> x <span class="o">=</span> rgamma<span class="p">(</span><span class="m">100000</span><span class="p">,</span> shape<span class="o">=</span><span class="m">1.0</span><span class="p">,</span> scale<span class="o">=</span><span class="m">10.0</span><span class="p">)</span>
<span class="o">&gt;</span> hist<span class="p">(</span>x<span class="p">)</span>
</pre></div>
</div>
<p>This will look something like:</p>
<div class="figure align-center" id="gamma-1-10-hist" style="width: 60%">
<a class="reference internal image-reference" href="../_images/gamma_1_10_hist.png"><img alt="gamma(1, 10) histogram" src="../_images/gamma_1_10_hist.png" style="width: 600px;" /></a>
<p class="caption">Gamma(1, 10) histogram</p>
</div>
<p>With a little more typing in the R prompt, we can get a more accurate
illustration of this prior:</p>
<div class="highlight-r"><div class="highlight"><pre><span class="o">&gt;</span> x.max <span class="o">=</span> qgamma<span class="p">(</span><span class="m">0.999</span><span class="p">,</span> shape<span class="o">=</span><span class="m">1.0</span><span class="p">,</span> scale<span class="o">=</span><span class="m">10.0</span><span class="p">)</span>
<span class="o">&gt;</span> x <span class="o">=</span> seq<span class="p">(</span>from<span class="o">=</span><span class="m">0</span><span class="p">,</span> to<span class="o">=</span>x.max<span class="p">,</span> by<span class="o">=</span>x.max<span class="o">/</span><span class="m">1000</span><span class="p">)</span>
<span class="o">&gt;</span> dens <span class="o">=</span> dgamma<span class="p">(</span>x<span class="p">,</span> shape<span class="o">=</span><span class="m">1.0</span><span class="p">,</span> scale<span class="o">=</span><span class="m">10.0</span><span class="p">)</span>
<span class="o">&gt;</span> plot<span class="p">(</span>x<span class="p">,</span> dens<span class="p">,</span> type<span class="o">=</span><span class="s">&#39;l&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>which will give us something like:</p>
<div class="figure align-center" id="gamma-1-10-plot" style="width: 60%">
<a class="reference internal image-reference" href="../_images/gamma_1_10_plot.png"><img alt="gamma(1, 10) plot" src="../_images/gamma_1_10_plot.png" style="width: 600px;" /></a>
<p class="caption">Gamma(1, 10)</p>
</div>
<p>We said that we were quite confident the parameter is between 5.0 and 15.0.
It looks like this prior puts too much prior probability on values less than 5
and greater than 15.
We can use R to see that the prior probability of this parameter being less
than 5.0 or greater than 15.0 is about 0.39 and 0.22, respectively:</p>
<div class="highlight-r"><div class="highlight"><pre><span class="o">&gt;</span> pgamma<span class="p">(</span><span class="m">5.0</span><span class="p">,</span> shape<span class="o">=</span><span class="m">1.0</span><span class="p">,</span> scale<span class="o">=</span><span class="m">10.0</span><span class="p">,</span> lower.tail<span class="o">=</span><span class="k-Variable">T</span><span class="p">)</span>
<span class="p">[</span><span class="m">1</span><span class="p">]</span> <span class="m">0.3934693</span>
<span class="o">&gt;</span> pgamma<span class="p">(</span><span class="m">15.0</span><span class="p">,</span> shape<span class="o">=</span><span class="m">1.0</span><span class="p">,</span> scale<span class="o">=</span><span class="m">10.0</span><span class="p">,</span> lower.tail<span class="o">=</span><span class="k-Variable">F</span><span class="p">)</span>
<span class="p">[</span><span class="m">1</span><span class="p">]</span> <span class="m">0.2231302</span>
</pre></div>
</div>
<p>So, it looks like we need to increase our prior knowledge. Let&#8217;s try a shape
parameter of 2.0 (we need to adjust the scale parameter to 5.0 to keep the mean
of 10.0):</p>
<div class="highlight-r"><div class="highlight"><pre><span class="o">&gt;</span> pgamma<span class="p">(</span><span class="m">5.0</span><span class="p">,</span> shape<span class="o">=</span><span class="m">2.0</span><span class="p">,</span> scale<span class="o">=</span><span class="m">5.0</span><span class="p">,</span> lower.tail<span class="o">=</span><span class="k-Variable">T</span><span class="p">)</span>
<span class="p">[</span><span class="m">1</span><span class="p">]</span> <span class="m">0.2642411</span>
<span class="o">&gt;</span> pgamma<span class="p">(</span><span class="m">15.0</span><span class="p">,</span> shape<span class="o">=</span><span class="m">2.0</span><span class="p">,</span> scale<span class="o">=</span><span class="m">5.0</span><span class="p">,</span> lower.tail<span class="o">=</span><span class="k-Variable">F</span><span class="p">)</span>
<span class="p">[</span><span class="m">1</span><span class="p">]</span> <span class="m">0.1991483</span>
</pre></div>
</div>
<p>Hmmm... Still too much prior probability on values outside of 5&#8211;15. Let&#8217;s try
a shape of 10.0:</p>
<div class="highlight-r"><div class="highlight"><pre><span class="o">&gt;</span> pgamma<span class="p">(</span><span class="m">5.0</span><span class="p">,</span> shape<span class="o">=</span><span class="m">10.0</span><span class="p">,</span> scale<span class="o">=</span><span class="m">1.0</span><span class="p">,</span> lower.tail<span class="o">=</span><span class="k-Variable">T</span><span class="p">)</span>
<span class="p">[</span><span class="m">1</span><span class="p">]</span> <span class="m">0.03182806</span>
<span class="o">&gt;</span> pgamma<span class="p">(</span><span class="m">15.0</span><span class="p">,</span> shape<span class="o">=</span><span class="m">10.0</span><span class="p">,</span> scale<span class="o">=</span><span class="m">1.0</span><span class="p">,</span> lower.tail<span class="o">=</span><span class="k-Variable">F</span><span class="p">)</span>
<span class="p">[</span><span class="m">1</span><span class="p">]</span> <span class="m">0.06985366</span>
</pre></div>
</div>
<p>Let&#8217;s assume this fits our prior expectation pretty well (i.e., we want to
state <em>a priori</em> that the probability of the prior being between 5 and 15 is
about 0.9).
Let&#8217;s take a look at this gamma prior with a shape and mean of 10.0:</p>
<div class="highlight-r"><div class="highlight"><pre><span class="o">&gt;</span> x.max <span class="o">=</span> qgamma<span class="p">(</span><span class="m">0.999</span><span class="p">,</span> shape<span class="o">=</span><span class="m">10.0</span><span class="p">,</span> scale<span class="o">=</span><span class="m">1.0</span><span class="p">)</span>
<span class="o">&gt;</span> x <span class="o">=</span> seq<span class="p">(</span>from<span class="o">=</span><span class="m">0</span><span class="p">,</span> to<span class="o">=</span>x.max<span class="p">,</span> by<span class="o">=</span>x.max<span class="o">/</span><span class="m">1000</span><span class="p">)</span>
<span class="o">&gt;</span> dens <span class="o">=</span> dgamma<span class="p">(</span>x<span class="p">,</span> shape<span class="o">=</span><span class="m">10.0</span><span class="p">,</span> scale<span class="o">=</span><span class="m">1.0</span><span class="p">)</span>
<span class="o">&gt;</span> plot<span class="p">(</span>x<span class="p">,</span> dens<span class="p">,</span> type<span class="o">=</span><span class="s">&#39;l&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-center" id="gamma-10-1-plot" style="width: 60%">
<a class="reference internal image-reference" href="../_images/gamma_10_1_plot.png"><img alt="gamma(10, 1) plot" src="../_images/gamma_10_1_plot.png" style="width: 600px;" /></a>
<p class="caption">Gamma(10, 1)</p>
</div>
<p>Hopefully this example gives you the necessary tools for choosing the shape and
scale parameters for a gamma-distributed prior that reflects your prior
uncertainty about a parameter.
Next, let&#8217;s talk specifically about choosing priors for the parameters of the
<a class="reference external" href="https://github.com/joaks1/dpp-msbayes.git">dpp-msbayes</a> model.</p>
</div>
</div>
<div class="section" id="important-priors-for-the-dpp-msbayes-model">
<h2>4.3.2. Important priors for the <a class="reference external" href="https://github.com/joaks1/dpp-msbayes.git">dpp-msbayes</a> model<a class="headerlink" href="#important-priors-for-the-dpp-msbayes-model" title="Permalink to this headline">¶</a></h2>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><a class="reference internal" href="#concentration-parameter-of-the-dirichlet-process" id="id6">Concentration parameter of the Dirichlet process</a></li>
<li><a class="reference internal" href="#population-size" id="id7">Population size</a></li>
<li><a class="reference internal" href="#divergence-time" id="id8">Divergence time</a></li>
<li><a class="reference internal" href="#bottleneck-proportions" id="id9">Bottleneck proportions</a></li>
</ul>
</div>
<div class="section" id="concentration-parameter-of-the-dirichlet-process">
<span id="concentration-parameter"></span><h3><a class="toc-backref" href="#id6">4.3.2.1. Concentration parameter of the Dirichlet process</a><a class="headerlink" href="#concentration-parameter-of-the-dirichlet-process" title="Permalink to this headline">¶</a></h3>
<p>We have to choose a gamma-distributed prior for the concentration parameter
(<img class="math" src="../_images/math/cfe3d773b9dc10efcc2fe954b87857e119645878.png" alt="\alpha"/>) of the Dirichlet process that controls the assignment of taxa
to divergence events.
From the &#8220;<a class="reference internal" href="background.html#dpp"><em>Dirichlet-process prior on divergence models</em></a>&#8221; section, we know that as the concentration parameter
decreases, we are putting more prior probability on models of divergence that
are more clustered (i.e., models with fewer shared divergence events).
Alternatively, as we increase <img class="math" src="../_images/math/cfe3d773b9dc10efcc2fe954b87857e119645878.png" alt="\alpha"/>, we place more prior probability
on divergence models with less co-divergence among taxa.</p>
<p><a class="reference external" href="http://joaks1.github.io/PyMsBayes/">PyMsBayes</a> comes with a program named <tt class="docutils literal"><span class="pre">dmc_dpp_summary.py</span></tt> that helps guide our choice
of the prior on the concentration parameter.
Let&#8217;s say we have sequence data from 10 taxa, and we want to know what
value of the concentration parameter corresponds with a prior mean
of 5 divergence events.
We can use <tt class="docutils literal"><span class="pre">dmc_dpp_summary.py</span></tt> to calclulate this by typing:</p>
<pre class="literal-block">
$ dmc_dpp_summary.py ncats 5 10
</pre>
<p>The output should look like:</p>
<div class="highlight-python"><div class="highlight"><pre>number of elements = 10
concentration parameter = 3.30149636133
expected number of categories = 5.0
</pre></div>
</div>
<p>This tells thus that divergence models generated under a Dirichlet process with
10 taxa and a concentration parameter of about 3.3 will have 5 divergence
events (parameters) on average.
We can confirm this by typing:</p>
<pre class="literal-block">
$ dmc_dpp_summary.py concentration 3.3 10
</pre>
<p>Which reports:</p>
<div class="highlight-python"><div class="highlight"><pre>number of elements = 10
concentration parameter = 3.3
expected number of categories = 4.99909319002
</pre></div>
</div>
<p>Ok, that&#8217;s useful, but what about the probability of other numbers of events?
Well, we can use the <tt class="docutils literal"><span class="pre">--reps</span></tt> option to tell <tt class="docutils literal"><span class="pre">dmc_dpp_summary.py</span></tt> to use simulations to
estimate such probabilities:</p>
<pre class="literal-block">
$ dmc_dpp_summary.py ncats 5 10 --reps 10000
</pre>
<p>This generates 10000 random divergence models under a Dirichlet process prior,
and reports the estimated prior probabilites for the possible numbers of
divergence events (it also reports the number of possible divergence models for
each number of divergence events):</p>
<div class="highlight-python"><div class="highlight"><pre>number of elements = 10
concentration parameter = 3.30149636133
expected number of categories = 5.0

Starting simulations to estimate probabilities...
Using seed 436471208

Estimated probabilities of the number of categories:
    p(ncats = 1) = 0.0024 (n = 1)
    p(ncats = 2) = 0.0280 (n = 511)
    p(ncats = 3) = 0.1012 (n = 9330)
    p(ncats = 4) = 0.2240 (n = 34105)
    p(ncats = 5) = 0.2912 (n = 42525)
    p(ncats = 6) = 0.2048 (n = 22827)
    p(ncats = 7) = 0.1080 (n = 5880)
    p(ncats = 8) = 0.0348 (n = 750)
    p(ncats = 9) = 0.0048 (n = 45)
    p(ncats = 10) = 0.0008 (n = 1)
</pre></div>
</div>
<p>This output tells us, for example, that the prior probability of a divergence
model with 2 divergence-time parameters, under a Dirichlet process with 10 taxa
and a concentation parameter of about 3.3, is approximately 0.028.
It also tells us that there are 511 possible divergence models with 2
divergence events (i.e., 511 different ways of assigning our taxa to 2
divergence events).</p>
<p>Above, we were just assuming the value of the concentration parameter is fixed
at 3.3.
This is all well and good, but in our <a class="reference external" href="https://github.com/joaks1/dpp-msbayes.git">dpp-msbayes</a> <a class="reference internal" href="configuration.html#config"><em>configuration
file</em></a>, we need to specify the shape and scale parameters for a gamma
prior on the concentration parameter.
No problem, <tt class="docutils literal"><span class="pre">dmc_dpp_summary.py</span></tt> can help us with that too.
If we want to essentially fix the concentration parameter to 3.3, we can
specify a very large shape parameter for the gamma prior:</p>
<pre class="literal-block">
$ dmc_dpp_summary.py ncats 5 10 --reps 10000 --shape 1000
</pre>
<p>The output will be something like:</p>
<pre class="literal-block">
number of elements = 10
concentration parameter = 3.30149636133
expected number of categories = 5.0
shape = <span class="codehlight">1000.0</span>
scale = <span class="codehlight">0.00330149636133</span>

Starting simulations to estimate probabilities...
Using seed 428982720

Estimated probabilities of the number of categories:
    p(ncats = 1) = 0.0012 (n = 1)
    p(ncats = 2) = 0.0292 (n = 511)
    p(ncats = 3) = 0.1104 (n = 9330)
    p(ncats = 4) = 0.2296 (n = 34105)
    p(ncats = 5) = 0.2756 (n = 42525)
    p(ncats = 6) = 0.2076 (n = 22827)
    p(ncats = 7) = 0.1048 (n = 5880)
    p(ncats = 8) = 0.0328 (n = 750)
    p(ncats = 9) = 0.0080 (n = 45)
    p(ncats = 10) = 0.0008 (n = 1)
</pre>
<p>As you can see, aside from some estimation error due to a finite number of
simulation replicates, the probabilities are nearly identical to our previous
prior where the concentration parameter was fixed to 3.3.
Notice that <tt class="docutils literal"><span class="pre">dmc_dpp_summary.py</span></tt> now reports the <tt class="docutils literal"><span class="pre">shape</span></tt> and <tt class="docutils literal"><span class="pre">scale</span></tt> parameters
(highlighted above); these correspond to the shape and scale parameters of a
gamma prior on the concentration parameter.
So, if we put the following in our configuration file:</p>
<pre class="literal-block">
concentrationShape = <span class="codehlight">1000.0</span>
concentrationScale = <span class="codehlight">0.00330149636133</span>
</pre>
<p>we will be using a Dirichlet process prior with a (nearly) fixed concentration
parameter of 3.3, which, on average, yields divergence models with 5 divergence
events.</p>
<p>Now, let&#8217;s say we have 20 pairs of taxa, and we want the prior mean for the
number of divergence events to be 15. We can uses <tt class="docutils literal"><span class="pre">dmc_dpp_summary.py</span></tt> to get an idea
of what such a Dirichlet process would look like if we essentially fix
the concentration parameter to the corresponding value associated with a
mean of 15 events:</p>
<pre class="literal-block">
$ dmc_dpp_summary.py ncats 15 20 --reps 10000 --shape 1000
</pre>
<p>The output will looks something like:</p>
<div class="highlight-python"><div class="highlight"><pre>number of elements = 20
concentration parameter = 25.5940195547
expected number of categories = 15.0
shape = 1000.0
scale = 0.0255940195547

Starting simulations to estimate probabilities...
Using seed 780386083

Estimated probabilities of the number of categories:
    p(ncats = 1) = 0.0000 (n = 1)
    p(ncats = 2) = 0.0000 (n = 524287)
    p(ncats = 3) = 0.0000 (n = 580606446)
    p(ncats = 4) = 0.0000 (n = 45232115901)
    p(ncats = 5) = 0.0000 (n = 749206090500)
    p(ncats = 6) = 0.0000 (n = 4306078895384)
    p(ncats = 7) = 0.0000 (n = 11143554045652)
    p(ncats = 8) = 0.0004 (n = 15170932662679)
    p(ncats = 9) = 0.0008 (n = 12011282644725)
    p(ncats = 10) = 0.0080 (n = 5917584964655)
    p(ncats = 11) = 0.0216 (n = 1900842429486)
    p(ncats = 12) = 0.0664 (n = 411016633391)
    p(ncats = 13) = 0.1108 (n = 61068660380)
    p(ncats = 14) = 0.1828 (n = 6302524580)
    p(ncats = 15) = 0.2072 (n = 452329200)
    p(ncats = 16) = 0.1932 (n = 22350954)
    p(ncats = 17) = 0.1252 (n = 741285)
    p(ncats = 18) = 0.0660 (n = 15675)
    p(ncats = 19) = 0.0168 (n = 190)
    p(ncats = 20) = 0.0008 (n = 1)
</pre></div>
</div>
<p>From this output, we can see that the number of possible models of divergence
is now enormous (e.g., there are more than 15 trillion ways to assign the 20
taxa to 8 divergence events!!).
We also see that by essentially fixing the concentration parameter (i.e., using
a large value of 1000 for the shape parameter of the gamma prior on the
concentration parameter), we will fail to sample many of the possible numbers
of divergence events during the ABC algorithm under reasonable computational
limits.
In such a case, a smaller value on the shape parameter is probably necessary
to make the Dirichlet process more diffuse:</p>
<pre class="literal-block">
$ dmc_dpp_summary.py ncats 15 20 --reps 10000 --shape 2

number of elements = 20
concentration parameter = 25.5940195547
expected number of categories = 15.0
shape = 2.0
scale = 12.7970097773

Starting simulations to estimate probabilities...
Using seed 619880880

Estimated probabilities of the number of categories:
    p(ncats = 1) = 0.0004 (n = 1)
    p(ncats = 2) = 0.0012 (n = 524287)
    p(ncats = 3) = 0.0048 (n = 580606446)
    p(ncats = 4) = 0.0056 (n = 45232115901)
    p(ncats = 5) = 0.0088 (n = 749206090500)
    p(ncats = 6) = 0.0140 (n = 4306078895384)
    p(ncats = 7) = 0.0212 (n = 11143554045652)
    p(ncats = 8) = 0.0300 (n = 15170932662679)
    p(ncats = 9) = 0.0320 (n = 12011282644725)
    p(ncats = 10) = 0.0520 (n = 5917584964655)
    p(ncats = 11) = 0.0596 (n = 1900842429486)
    p(ncats = 12) = 0.0876 (n = 411016633391)
    p(ncats = 13) = 0.0932 (n = 61068660380)
    p(ncats = 14) = 0.1092 (n = 6302524580)
    p(ncats = 15) = 0.1244 (n = 452329200)
    p(ncats = 16) = 0.1264 (n = 22350954)
    p(ncats = 17) = 0.1100 (n = 741285)
    p(ncats = 18) = 0.0716 (n = 15675)
    p(ncats = 19) = 0.0356 (n = 190)
    p(ncats = 20) = 0.0124 (n = 1)
</pre>
<p>We can see from the output above, that with a shape parameter of 2.0 for the
gamma prior on the concentration parameter, the prior probability of the number
of divergence events is now more spread out.</p>
<div class="keypoint admonition important" id="too-many-taxa">
<p class="first admonition-title">Important</p>
<p class="last">Given the number of possible divergence models is now over 50 trillion
(!!), it is clear that the naive ABC rejection algorithm implemented in
<a class="reference external" href="http://msbayes.sourceforge.net/">msBayes</a> and <a class="reference external" href="https://github.com/joaks1/dpp-msbayes.git">dpp-msbayes</a> will fail to sample most of these models
within reasonable computational limits.
Thus, it is questionable whether either method is appropriate when the
number of taxa is around 15 or more.
If you use either method with this many pairs of taxa, you should run
multiple replicates, each with large numbers of samples from the prior, to
make sure your estimates are stabilizing as the samples increase within
each run, and converging to similar values across runs.</p>
</div>
<p>The examples above were to illustrate the tools available to help you select
a prior on the concentration parameter.
You will need to decide what prior is appropriate to represent your prior
expectations for your particular system.
Whatever gamma-distributed prior you choose for your data, you need to
update your <a class="reference internal" href="configuration.html#config"><em>configuration file</em></a> accordingly:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">concentrationShape</span> <span class="o">=</span> <span class="mf">2.0</span>
<span class="n">concentrationScale</span> <span class="o">=</span> <span class="mf">12.797</span>
</pre></div>
</div>
<div class="section" id="an-important-point-about-the-concentration-parameter">
<h4>4.3.2.1.1. <span class="hlight">An important point about the concentration parameter</span><a class="headerlink" href="#an-important-point-about-the-concentration-parameter" title="Permalink to this headline">¶</a></h4>
<p>It is important to note that values of the DPP concentration parameter are
always specific to the number taxa.
For example, above we saw that for 10 taxa, a concentration parameter
of 3.3 corresponded to a prior mean of 5 divergence events.
However, when the number of taxa is 20, a concentration parameter of
3.3 does <strong>NOT</strong> correspond to a prior mean of 5:</p>
<pre class="literal-block">
$ dmc_dpp_summary.py concentration 3.3 20

number of elements = 20
concentration parameter = 3.3
expected number of categories = 6.90365997028
</pre>
<p>It actually corresponds to a prior mean of about 6.9.
So, you cannot simply choose your &#8220;favorite&#8221; prior for the concentration
parameter and apply it blindly for all datasets.
When you are analyzing a dataset with a different number of taxa, you need to
reassess your prior on the concentration parameter.</p>
</div>
</div>
<div class="section" id="population-size">
<span id="id3"></span><h3><a class="toc-backref" href="#id7">4.3.2.2. Population size</a><a class="headerlink" href="#population-size" title="Permalink to this headline">¶</a></h3>
<p>Another important parameter for which we need to choose a prior is the
effective population size of the ancestral and descendant populations
in the model.
See the following sections for more information about the role of the
population-size parameters in the model and how to control them:</p>
<ul class="simple">
<li><a class="reference internal" href="configuration.html#theta-parameterization"><em>parameterization</em></a></li>
<li><a class="reference internal" href="configuration.html#theta-prior"><em>theta configuration</em></a></li>
<li><a class="reference internal" href="configuration.html#ancestral-theta-prior"><em>ancestral theta configuration</em></a></li>
</ul>
<p>The effective population sizes are scaled by the per-site mutation rate
(<img class="math" src="../_images/math/6e853ba0c7899c7dec1c8a89d9a127a59f8bd7d8.png" alt="\mu"/>): <img class="math" src="../_images/math/9bc345c0c02801cf31d9f3d64d856b0df16d5df7.png" alt="4\effectivePopSize\mutationRate"/>.
Thus, for example, if we expect, <em>a priori</em>, that our populations are no bigger
than 100,000 individuals, and the per-site mutation rate is no faster than
<img class="math" src="../_images/math/ba75d43a068a21d86e405be697f88fcdf9f9c076.png" alt="1 \times 10^{-8}"/> per generation, then we do not expect the effective
population size to exceed <img class="math" src="../_images/math/d2c7edfa55f56dc9824120611ece82d097cabbfb.png" alt="4(100000)(1 \times 10^{-8}) = 0.004"/>.</p>
<div class="keypoint admonition note" id="time-unit-note">
<p class="first admonition-title">Note</p>
<p class="last">The per-site mutation rate should be in units of generations.</p>
</div>
<p>If we expect the effective population size to be less than 0.004, but
we do not know how much less, perhaps an exponential distribution (i.e., a
gamma distribution with a shape parameter of 1) is a reasonable prior.</p>
<p>Let&#8217;s use some of the tools we learned about in the <a class="reference internal" href="#gamma-in-r"><em>section introducing
gamma distributions</em></a> to choose a reasonable prior for this example.
A gamma with a shape parameter of 1 is an exponential, but we still need to
choose our scale parameter.
Let&#8217;s see how much of our prior probability will fall on values greater
than 0.004 if we use an exponential with a mean of 0.002.
Because the shape parameter is 1, this means the scale parameter is simply
0.002 (remember, the mean is simply the product of the shape and scale):</p>
<div class="highlight-r"><div class="highlight"><pre><span class="o">&gt;</span> pgamma<span class="p">(</span><span class="m">0.004</span><span class="p">,</span> shape<span class="o">=</span><span class="m">1.0</span><span class="p">,</span> scale<span class="o">=</span><span class="m">0.002</span><span class="p">,</span> lower.tail<span class="o">=</span><span class="k-Variable">F</span><span class="p">)</span>
<span class="p">[</span><span class="m">1</span><span class="p">]</span> <span class="m">0.1353353</span>
</pre></div>
</div>
<p>Perhaps this seems like too much prior probability greater than 0.004; let&#8217;s
try a scale parameter of 0.001:</p>
<div class="highlight-r"><div class="highlight"><pre><span class="o">&gt;</span> pgamma<span class="p">(</span><span class="m">0.004</span><span class="p">,</span> shape<span class="o">=</span><span class="m">1.0</span><span class="p">,</span> scale<span class="o">=</span><span class="m">0.001</span><span class="p">,</span> lower.tail<span class="o">=</span><span class="k-Variable">F</span><span class="p">)</span>
<span class="p">[</span><span class="m">1</span><span class="p">]</span> <span class="m">0.01831564</span>
</pre></div>
</div>
<p>If this seems to fit our prior expectations, we can take a look at this prior:</p>
<div class="highlight-r"><div class="highlight"><pre>
</pre></div>
</div>
<p>x.max = qgamma(0.999, shape=1.0, scale=0.001)
x = seq(from=0, to=x.max, by=x.max/1000)
dens = dgamma(x, shape=1.0, scale=0.001)
plot(x, dens, type=&#8217;l&#8217;)</p>
<p>which will give us something like:</p>
<div class="figure align-center" id="gamma-1-001-plot" style="width: 60%">
<a class="reference internal image-reference" href="../_images/gamma_1_001_plot.png"><img alt="gamma(1, 0.001) plot" src="../_images/gamma_1_001_plot.png" style="width: 600px;" /></a>
<p class="caption">Gamma(1, 0.001)</p>
</div>
<p>If you feel you have more prior knowledge than is represented by this
exponential (for example, perhaps you expect the effective population size to
be greater than 0.0005), then you can increase the shape parameter accordingly,
until you end up with a distribution that fits your prior uncertainty.
You can use the examples in the <a class="reference internal" href="#gamma-in-r"><em>section introducing gamma
distributions</em></a> as a guide for doing this.
When you choose your prior distribution, simply update your <a class="reference internal" href="configuration.html#config"><em>configuration
file</em></a> accordingly:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">thetaShape</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">thetaScale</span> <span class="o">=</span> <span class="mf">0.001</span>
</pre></div>
</div>
</div>
<div class="section" id="divergence-time">
<span id="id4"></span><h3><a class="toc-backref" href="#id8">4.3.2.3. Divergence time</a><a class="headerlink" href="#divergence-time" title="Permalink to this headline">¶</a></h3>
<p>We also need to choose a gamma-distributed prior for the divergence
times of the pairs of populations.
See the following sections for more information about how time is
scaled in <a class="reference external" href="http://msbayes.sourceforge.net/">msBayes</a> and <a class="reference external" href="https://github.com/joaks1/dpp-msbayes.git">dpp-msbayes</a>:</p>
<ul class="simple">
<li><a class="reference internal" href="configuration.html#timescale-setting"><em>time-scale setting</em></a></li>
<li><a class="reference internal" href="configuration.html#divergence-time-prior"><em>divergence time configuration</em></a></li>
</ul>
<p>For now, let&#8217;s assume we are using the <tt class="docutils literal"><span class="pre">timeInSubsPerSite</span> <span class="pre">=</span> <span class="pre">1</span></tt> setting so
that time is (reasonably) scaled by the expected substitutions per site.
Let&#8217;s say we are confident that all of our pairs of taxa diverged within the
past 10 million generations, and we expect their per-site mutation rates are no
faster than <img class="math" src="../_images/math/ba75d43a068a21d86e405be697f88fcdf9f9c076.png" alt="1 \times 10^{-8}"/> per generation, then the number of
substitutions per site that have accumulated since the populations diverged is
probably no greater than <img class="math" src="../_images/math/5935a2aeeb5f052c51f835ec6770da7be2faf368.png" alt="(10^{7})(10^{-8}) = 0.1"/>.</p>
<p>If we expect most of our species pairs diverged recently, but probably no
greater than 0.1 substitutions-per-site ago, perhaps an exponential prior
(i.e., a gamma prior with a shape of 1) is a reasonable choice.
Again, let&#8217;s figure out a value for the scale parameter that limits
the prior probability of values greater than 0.1 to meet our prior
expectations. Let&#8217;s try scale of 0.05:</p>
<div class="highlight-r"><div class="highlight"><pre><span class="o">&gt;</span> pgamma<span class="p">(</span><span class="m">0.1</span><span class="p">,</span> shape<span class="o">=</span><span class="m">1.0</span><span class="p">,</span> scale<span class="o">=</span><span class="m">0.05</span><span class="p">,</span> lower.tail<span class="o">=</span><span class="k-Variable">F</span><span class="p">)</span>
<span class="p">[</span><span class="m">1</span><span class="p">]</span> <span class="m">0.1353353</span>
</pre></div>
</div>
<p>If ~ 0.14 is seems like too much prior probability for values greater than
0.1, then we can reduce the scale parameter until we find a value that
is in line with our prior uncertainty about divergence times.
Perhaps a scale of 0.03 (prior probability of 0.036 for values greater than
0.1) is a good &#8220;fit.&#8221;</p>
<p>Again, if you have more prior certainty about divergence times, increase the
shape parameter and adjust the scale parameter until you find a distribution
that fits your prior knowledge.
When you choose your prior distribution, simply update your <a class="reference internal" href="configuration.html#config"><em>configuration
file</em></a> accordingly:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">tauShape</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">tauScale</span> <span class="o">=</span> <span class="mf">0.03</span>
</pre></div>
</div>
<div class="keypoint admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If we use the <tt class="docutils literal"><span class="pre">timeInSubsPerSite</span> <span class="pre">=</span> <span class="pre">0</span></tt> setting, time is scaled by the
mutation rate <strong>AND</strong> the mean of the prior on population size
(<a class="reference internal" href="configuration.html#theta-prior"><em>thetaShape/thetaScale</em></a>).
We would select our divergence-time prior as above, but we would have to
make sure we are working in units of <img class="math" src="../_images/math/8b24632d511826302cb5f2c39ee52e2781447cd8.png" alt="\globalcoalunit"/> generations...
and if we change the prior on population size
(<a class="reference internal" href="configuration.html#theta-prior"><em>thetaShape/thetaScale</em></a>), we have to change the prior on
divergence times accordingly.
See the <a class="reference internal" href="configuration.html#timescale-setting"><em>section about the time scale setting</em></a> for
more information about such scaling.
However, there is no reason to scale time by both the mutation rate and the
prior on population size, other than to make things more difficult.</p>
</div>
</div>
<div class="section" id="bottleneck-proportions">
<span id="id5"></span><h3><a class="toc-backref" href="#id9">4.3.2.4. Bottleneck proportions</a><a class="headerlink" href="#bottleneck-proportions" title="Permalink to this headline">¶</a></h3>
<p>We have the option of specifying a beta-distributed prior to control the
magnitude of post-divergence bottlenecks in the descendant populations.
Please see the following sections for more information about the role of the
bottleneck parameters in the model and how to control them:</p>
<ul class="simple">
<li><a class="reference internal" href="configuration.html#bottleneck-parameterization"><em>bottleneck parameterization</em></a></li>
<li><a class="reference internal" href="configuration.html#bottleneck-prior"><em>bottleneck configuration</em></a></li>
</ul>
<p>If we want to remove bottlnecks from the model, we update our
<a class="reference internal" href="configuration.html#config"><em>configuration file</em></a> to:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">bottleProportionShapeA</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">bottleProportionShapeB</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>
</div>
<p>The beta distribution is a very flexible continuous probability distribution
for variables between 0 and 1.
Because the bottleneck parameters are proportions (the proportion of the
effective population size that remains during the bottleneck), a
beta-distributed prior is a suitable choice.
The beta distribution has two shape parameters <img class="math" src="../_images/math/81b3b4cbfebfd2f8afd3c1d9261be266918d82b0.png" alt="\bshapea"/> and
<img class="math" src="../_images/math/824646ea974998c990387705f5497be9e3e5f3be.png" alt="\bshapeb"/>.
When <img class="math" src="../_images/math/81b3b4cbfebfd2f8afd3c1d9261be266918d82b0.png" alt="\bshapea"/> and <img class="math" src="../_images/math/824646ea974998c990387705f5497be9e3e5f3be.png" alt="\bshapeb"/> are both 1, the beta converges
to a uniform distribution.
We can confirm this with a little R code:</p>
<div class="highlight-r"><div class="highlight"><pre><span class="o">&gt;</span> x <span class="o">=</span> seq<span class="p">(</span><span class="m">0</span><span class="p">,</span> <span class="m">1</span><span class="p">,</span> by<span class="o">=</span><span class="m">1</span><span class="o">/</span><span class="m">1000</span><span class="p">)</span>
<span class="o">&gt;</span> dens <span class="o">=</span> dbeta<span class="p">(</span>x<span class="p">,</span> shape1<span class="o">=</span><span class="m">1</span><span class="p">,</span> shape2<span class="o">=</span><span class="m">1</span><span class="p">)</span>
<span class="o">&gt;</span> plot<span class="p">(</span>x<span class="p">,</span> dens<span class="p">,</span> type<span class="o">=</span><span class="s">&#39;l&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>which should look like a nice uniform distribution from 0 to 1:</p>
<div class="figure align-center" id="beta-1-1-plot" style="width: 60%">
<a class="reference internal image-reference" href="../_images/beta_1_1_plot.png"><img alt="beta(1, 1) plot" src="../_images/beta_1_1_plot.png" style="width: 600px;" /></a>
<p class="caption">Beta(1, 1)</p>
</div>
<p>If we want to place more prior weight on larger proportions (i.e., the bottlenecks are less severe),
we can increase <img class="math" src="../_images/math/81b3b4cbfebfd2f8afd3c1d9261be266918d82b0.png" alt="\bshapea"/>. For example, let&#8217;s try <img class="math" src="../_images/math/2c01ea77b534b740b115056fb3156b0a604e6c6e.png" alt="\bshapea = 5"/> looks like:</p>
<div class="highlight-r"><div class="highlight"><pre><span class="o">&gt;</span> x <span class="o">=</span> seq<span class="p">(</span><span class="m">0</span><span class="p">,</span> <span class="m">1</span><span class="p">,</span> by<span class="o">=</span><span class="m">1</span><span class="o">/</span><span class="m">1000</span><span class="p">)</span>
<span class="o">&gt;</span> dens <span class="o">=</span> dbeta<span class="p">(</span>x<span class="p">,</span> shape1<span class="o">=</span><span class="m">5</span><span class="p">,</span> shape2<span class="o">=</span><span class="m">1</span><span class="p">)</span>
<span class="o">&gt;</span> plot<span class="p">(</span>x<span class="p">,</span> dens<span class="p">,</span> type<span class="o">=</span><span class="s">&#39;l&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>which should look like:</p>
<div class="figure align-center" id="beta-5-1-plot" style="width: 60%">
<a class="reference internal image-reference" href="../_images/beta_5_1_plot.png"><img alt="beta(5, 1) plot" src="../_images/beta_5_1_plot.png" style="width: 600px;" /></a>
<p class="caption">Beta(5, 1)</p>
</div>
<p>Likewise, we could place a strong prior on severe bottlenecks (i.e., small proportions) if
we increase <img class="math" src="../_images/math/824646ea974998c990387705f5497be9e3e5f3be.png" alt="\bshapeb"/>. For example, let&#8217;s try <img class="math" src="../_images/math/442ee0a760b2bc926f6a6a9dce5dac97334aff69.png" alt="\bshapeb = 10"/>:</p>
<div class="highlight-r"><div class="highlight"><pre><span class="o">&gt;</span> x <span class="o">=</span> seq<span class="p">(</span><span class="m">0</span><span class="p">,</span> <span class="m">1</span><span class="p">,</span> by<span class="o">=</span><span class="m">1</span><span class="o">/</span><span class="m">1000</span><span class="p">)</span>
<span class="o">&gt;</span> dens <span class="o">=</span> dbeta<span class="p">(</span>x<span class="p">,</span> shape1<span class="o">=</span><span class="m">5</span><span class="p">,</span> shape2<span class="o">=</span><span class="m">1</span><span class="p">)</span>
<span class="o">&gt;</span> plot<span class="p">(</span>x<span class="p">,</span> dens<span class="p">,</span> type<span class="o">=</span><span class="s">&#39;l&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>which should look like:</p>
<div class="figure align-center" id="beta-1-10-plot" style="width: 60%">
<a class="reference internal image-reference" href="../_images/beta_1_10_plot.png"><img alt="beta(1, 10) plot" src="../_images/beta_1_10_plot.png" style="width: 600px;" /></a>
<p class="caption">Beta(1, 10)</p>
</div>
<p><img class="math" src="../_images/math/81b3b4cbfebfd2f8afd3c1d9261be266918d82b0.png" alt="\bshapea"/> and <img class="math" src="../_images/math/824646ea974998c990387705f5497be9e3e5f3be.png" alt="\bshapeb"/> can be any positive number, and a beta
distribution of just about any shape is possible, so you have a lot of
flexibility to represent your prior knowledge about bottleneck
severity.</p>
<p>If, for example, the <a class="reference internal" href="#beta-5-1-plot"><em>beta(</em></a><img class="math" src="../_images/math/ce8defc92f02d15f242239bbf844229bbdd8b35f.png" alt="\bshapea=5, \bshapeb=1"/>)
distribution is a good match to your prior uncertainty, you would
specify this prior in the configuration file by:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">bottleProportionShapeA</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">bottleProportionShapeB</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="get-example-data.html" title="4.4. Getting the exampe data"
             >next</a> |</li>
        <li class="right" >
          <a href="configuration.html" title="4.2. The Configuration File"
             >previous</a> |</li>
<li><a href="../index.html">Home</a>&nbsp;|</li>
<li><a href="../intro/installation.html">Install</a>&nbsp;|</li>
<li><a href="../doc.html">Documentation</a>&nbsp;|</li>

          <li><a href="index.html" >4. PyMsBayes Tutorials</a> &raquo;</li> 
      </ul>
    </div>
<div class="footer">
<span class="creativecommons">
<a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
</span>
</div>

  </body>
</html>